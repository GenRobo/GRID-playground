{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid.robot.arm.isaac_arm import IsaacArm\n",
    "from grid.utils.types import Position, Orientation\n",
    "from grid.model.perception.detection.owlv2 import OWLv2\n",
    "from grid.utils.types import Velocity\n",
    "from grid.utils import log\n",
    "\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2516d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = IsaacArm()\r\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf8cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ae8190f93c4790ae98c10a14dfceca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d772b26236934285a33135b564378e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd5eec72c054066ae40b92aa644c39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43712dae667048b6a8f4a390f8393e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f71847481846dab097e360b2f7e945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/67.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120c5a03c2ef4f25ba30a6e41ce26885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd163cd8f3974454bc90d6549072b404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ac011ca4c444cb4b12ad012b7164d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/620M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj = \"green cube\"\r\n",
    "    \r\n",
    "# Load the object detection model\r\n",
    "det_model = OWLv2(use_local=True)\r\n",
    "\r\n",
    "goal_quat_np = np.array([0.0, 0.0, 0.0, 1.0])  # Assuming quaternion interpolation isn't needed\r\n",
    "step_size = 0.15  # Define a step size for movement\r\n",
    "step_size_z = 0.025  # Define a step size for z movement\r\n",
    "focal_length = 24. # Define the focal length of the camera\r\n",
    "horizontal_aperture = 20.955 # Define the horizontal aperture of the camera\r\n",
    "image_width = 256. # Define the image width\r\n",
    "image_height = 256. # Define the image height\r\n",
    "t = [1.5, 0, 0.7] # Define the translation vector\r\n",
    "q = [0, -0.3, 0, 1] # Define the quaternion\r\n",
    "fx = (focal_length / horizontal_aperture) * image_width # Define the focal length in x\r\n",
    "fy = (focal_length / horizontal_aperture) * image_height # Define the focal length in y\r\n",
    "cx = image_width / 2 # Define the center of the image in x\r\n",
    "cy = image_height / 2 # Define the center of the image in y\r\n",
    "goal_z = 0.13   # Define the goal z position\r\n",
    "# Define the rotation matrix\r\n",
    "rot_matrix = np.array([[1 - 2*(q[1]**2 + q[2]**2), 2*(q[0]*q[1] - q[2]*q[3]), 2*(q[0]*q[2] + q[1]*q[3])],\r\n",
    "                        [2*(q[0]*q[1] + q[2]*q[3]), 1 - 2*(q[0]**2 + q[2]**2), 2*(q[1]*q[2] - q[0]*q[3])],\r\n",
    "                        [2*(q[0]*q[2] - q[1]*q[3]), 2*(q[1]*q[2] + q[0]*q[3]), 1 - 2*(q[0]**2 + q[1]**2)]])\r\n",
    "# Define the world to camera transformation matrix\r\n",
    "T_world_from_cam = np.array([[rot_matrix[0, 0], rot_matrix[0, 1], rot_matrix[0, 2], t[0]],\r\n",
    "                                [rot_matrix[1, 0], rot_matrix[1, 1], rot_matrix[1, 2], t[1]],\r\n",
    "                                [rot_matrix[2, 0], rot_matrix[2, 1], rot_matrix[2, 2], t[2]],\r\n",
    "                                [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_center(box, image_size):\r\n",
    "    \"\"\"\r\n",
    "    Calculate the center of a single bounding box given in xyxy format.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        box (list or np.ndarray): A bounding box with format [x_min, y_min, x_max, y_max].\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "        tuple: Center point (x_center, y_center).\r\n",
    "    \"\"\"\r\n",
    "    x_min, y_min, x_max, y_max = box\r\n",
    "    if image_size[0] * image_size[1] * .2 < (x_max-x_min) * (y_max-y_min):\r\n",
    "        return -1, -1\r\n",
    "    x_center = (x_min + x_max) / 2\r\n",
    "    y_center = (y_min + y_max) / 2\r\n",
    "    return x_center, y_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-21T14:39:53Z WARN  re_log_types::path::parse_path] When parsing the entity path \"viz/owlv2/detect_green cube\": Unescaped whitespace. The path will be interpreted as /viz/owlv2/detect_green\\ cube\n",
      "[2025-05-21T14:39:53Z WARN  re_log_types::path::parse_path] When parsing the entity path \"viz/owlv2/detect_green cube/bboxes\": Unescaped whitespace. The path will be interpreted as /viz/owlv2/detect_green\\ cube/bboxes\n"
     ]
    }
   ],
   "source": [
    "# Get the images from the camera\r\n",
    "rgb, depth = None, None\r\n",
    "while rgb is None or rgb.data is None or depth is None or depth.data is None:\r\n",
    "    print (\"Waiting for image\")\r\n",
    "    rgb = agent.getImage(\"camera_rgb_0\")\r\n",
    "    depth = agent.getImage(\"camera_depth_0\")\r\n",
    "    time.sleep(0.2)\r\n",
    "    \r\n",
    "log(\"grid/rgb_img\", rgb)\r\n",
    "log(\"grid/depth_img\", depth)\r\n",
    "\r\n",
    "data = rgb.data\r\n",
    "# Run the object detection model\r\n",
    "boxes, scores, labels = det_model.run(rgbimage=data[:, :, :3], prompt=obj)\r\n",
    "while boxes is None or len(boxes) == 0:\r\n",
    "    boxes, scores, labels = det_model.run(rgbimage=data[:, :, :3], prompt=obj)\r\n",
    "\r\n",
    "i = np.argmax(scores)\r\n",
    "# Get the center of the bounding box\r\n",
    "center_x, center_y = get_box_center(boxes[i], [data.shape[1], data.shape[0]])\r\n",
    "if center_x == -1 and center_y == -1:\r\n",
    "    print (\"Object too big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 3D coordinates (camera -> world)\r\n",
    "depth_data = depth.data[:, :, 0]\r\n",
    "Z = depth_data[int(center_y), int(center_x)]\r\n",
    "X_c = ((center_x - cx) / fx) * Z\r\n",
    "Y_c = ((center_y - cy) / fy) * Z\r\n",
    "Z_c = Z\r\n",
    "\r\n",
    "camera_point_h = np.array([X_c, Y_c, Z_c, 1.0])\r\n",
    "world_point_h = T_world_from_cam @ camera_point_h\r\n",
    "X_w, Y_w, Z_w = world_point_h[:3]\r\n",
    "\r\n",
    "goal_pos_np = np.array([X_w-0.25, Y_w-0.1, Z_w]) # offset for (cube side / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the robot to the (x, y) position of the object\r\n",
    "\r\n",
    "# Iterate to reach the goal position\r\n",
    "for i in range(250):\r\n",
    "    curr_pos = agent.getPosition()\r\n",
    "    while curr_pos is None or curr_pos.x_val is None or curr_pos.y_val is None:\r\n",
    "        curr_pos = agent.getPosition()\r\n",
    "        time.sleep(0.1)\r\n",
    "\r\n",
    "    curr_pos_np = np.array([curr_pos.x_val, curr_pos.y_val, curr_pos.z_val])\r\n",
    "            \r\n",
    "    # Compute delta position\r\n",
    "    direction = (goal_pos_np - curr_pos_np) \r\n",
    "    delta_pos = direction * step_size  # Move step_size or remaining distance\r\n",
    "    \r\n",
    "    # Move towards the goal with delta position\r\n",
    "    agent.moveToDeltaPose(Position(delta_pos[0], delta_pos[1], 0.), Orientation(*goal_quat_np))\r\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the robot to the goal z position\r\n",
    "agent.release()\r\n",
    "# Iterate to reach the goal position\r\n",
    "for i in range(700):\r\n",
    "    curr_pos = agent.getPosition()\r\n",
    "    while curr_pos is None or curr_pos.x_val is None or curr_pos.y_val is None:\r\n",
    "        curr_pos = agent.getPosition()\r\n",
    "        time.sleep(0.1)\r\n",
    "\r\n",
    "    delta = (goal_z - curr_pos.z_val)\r\n",
    "    delta_pos = (goal_z - curr_pos.z_val) * step_size_z\r\n",
    "\r\n",
    "    if abs(delta) < 0.01:\r\n",
    "        print(\"Z Reached\")\r\n",
    "        break\r\n",
    "    # Move towards the goal with delta position\r\n",
    "    agent.moveToDeltaPose(Position(0., 0., delta_pos), Orientation(*goal_quat_np))\r\n",
    "    time.sleep(0.1)\r\n",
    "\r\n",
    "agent.grasp()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
