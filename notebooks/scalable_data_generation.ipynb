{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ca3773-1b2d-4284-8d3e-ed8008538af6",
   "metadata": {},
   "source": [
    "# **Data Generation Pipeline Tutorial**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d3e2c-cbbe-4607-b599-0a418c42a8d8",
   "metadata": {},
   "source": [
    "Scalable data collection is crucial in robotics because it enables rapid prototyping, robust model training, and extensive testing across various real-world scenarios. Traditional data collection can be time-consuming, resource-intensive, and limited by physical constraints. GRID overcomes these challenges by providing a virtual environment where users can quickly simulate and customize complex scenarios, configure sensors, and automate data generation at scale. This means faster iterations, broader coverage of edge cases, and robust datasets that accelerate the development of reliable, intelligent and safe robotics systems.\n",
    "\n",
    "In this tutorial, we will guide you through a comprehensive end-to-end workflow for generating diverse multimodal sensor data at scale on the GRID platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552139d2-2b97-4930-ad54-9f4677c25fee",
   "metadata": {},
   "source": [
    "Let’s begin by setting up the environment, configuring the robot, and defining simulation parameters. We’ll generate a trajectory, set up sensors, and enable autonomous data collection. Finally, we’ll see how GRID Enterprise scales this process for efficient, large-scale data generation.\n",
    "\n",
    "### Tutorial Outline\n",
    "\n",
    "1. **Scene Selection and Customisation**: Initialize environment, configure robot and sensors, customize weather, wind, and time settings.\n",
    "2. **Trajectory Generation and Sensor Selection**: Generate random path, extract waypoints, and select RGB, LiDAR, and IMU modalities.\n",
    "3. **Autonomous Data Generation**: Gather data along the trajectory, log, and visualize.\n",
    "4. **Scaling with GRID Enterprise**: Parallelize data generation for large-scale projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191a0d7-6b2f-419d-83d7-590d4a740d58",
   "metadata": {},
   "source": [
    "## Scene Selection and Customisation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4a9d5-3a37-438b-a115-ec75d2c6eace",
   "metadata": {},
   "source": [
    "GRID offers multiple customizable environments, with options to choose different robots and sensor configurations.\n",
    "\n",
    "For this demo, we will set up a neighborhood scenario using the Clearpath Husky Robot equipped with an RGB camera, LiDAR, and IMU sensors.\n",
    "\n",
    "Once the session has started, let us go ahead and import our standard modules and initialise our robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03ef1a-56a0-4462-9075-ebb7d0878f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the robot\n",
    "import airgen\n",
    "from airgen.utils.collect import data_collector\n",
    "from airgen import WeatherParameter, Vector3r\n",
    "from typing import List, Tuple, Dict, Any, Optional, Callable\n",
    "import rerun as rr\n",
    "import random, h5py, numpy as np\n",
    "\n",
    "from grid.robot.wheeled.airgen_car import AirGenCar\n",
    "airgen_car_0 = AirGenCar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3717af3-398e-4a54-b9d6-0ac32e25d8b4",
   "metadata": {},
   "source": [
    "Once the session is initialized, we can further customize the environment's physical characteristics, such as wind speed, time of day, and weather conditions. For example, let's add fog to the simulation, set the time to around sunset, and adjust the wind speed to 5 m/s. Learn more about the configuration parameters in our [docs](https://docs.scaledfoundations.ai/airgen/features/environment/weather.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8e0ab-bebe-403c-9f91-c3d50659fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the weather, wind, and timeofday parameters\n",
    "\n",
    "client = airgen_car_0.client\n",
    "\n",
    "client.simEnableWeather(True)\n",
    "client.simSetWeatherParameter(WeatherParameter.Fog, 1.0) # adds fog to the scene\n",
    "# client.simSetWind(airgen.Vector3r(5, 0, 0)) # sets a 5 m/s wind in X direction, only supported for drones for now\n",
    "client.simSetTimeOfDay(True, \"2024-07-22 17:00:00\") # sets the time of day to be around sunset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c93b1-8d72-4b39-800e-32501dbab87a",
   "metadata": {},
   "source": [
    "## Trajectory Generation and Sensor Selection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b848cb2-bd85-4e1b-80aa-230de97070f6",
   "metadata": {},
   "source": [
    "We will begin by initializing random source and destination points for the robot's path. The `simPlanPathToRandomFreePoint` function searches for random start and end points within a specified radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbe4f7-8ec7-4c38-9acb-6df55df044fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_radius = 100 # distance in meters\n",
    "path = client.simPlanPathToRandomFreePoint(search_radius, smooth_path=True, draw_path=True) # generates the trajectory of points\n",
    "\n",
    "points = []\n",
    "for point in path:\n",
    "    points.append(airgen.Vector3r(point['x_val'], point['y_val'], point['z_val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f4904-da1e-4c3d-9a7b-57c0e25e1db8",
   "metadata": {},
   "source": [
    "Next, we will define the modalities of data to be collected. In this tutorial, we will gather RGB, LiDAR, and IMU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc0fdc-7d01-4c4f-9edc-49d3764998d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSensors(client: airgen.VehicleClient) -> dict:\n",
    "    sensor_data = {}\n",
    "    sensor_data[\"imu\"] = client.getImuData()\n",
    "    sensor_data['rgb'] = client.getImages(\"front_center\",[airgen.ImageType.Scene])[0]\n",
    "    sensor_data[\"lidar\"] = client.getLidarData()\n",
    "    return sensor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426885bc-fb50-4c41-9fe0-0b72e2b44295",
   "metadata": {},
   "source": [
    "## Autonomous Data Generation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29322a-0532-4183-ad92-fcfaf1dee28d",
   "metadata": {},
   "source": [
    "With the sensor configurations, trajectory, and environment setup in place, we can now enable the robot to collect data autonomously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148dc9f-6153-4fcd-ab05-43ec1abd706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@data_collector(readSensors, time_delta=0.1)\n",
    "def move_task(\n",
    "    client: airgen.MultirotorClient, position: Tuple[float], **kwargs\n",
    ") -> None | Tuple[None, List[dict]]:\n",
    "    client.moveOnPath(points, velocity=5.0)\n",
    "\n",
    "\n",
    "_, sensor_data = move_task(client, (0, 0, -10), _collect_data=True)\n",
    "for i, data in enumerate(sensor_data):\n",
    "    lidar = data[\"lidar\"]\n",
    "    rgb, _ = data[\"rgb\"]\n",
    "    rr.log(\"grid/imagery\",rr.Image(rgb))\n",
    "    rr.log(\"pointcloud\", rr.Points3D(np.array(lidar.point_cloud).reshape(-1, 3)))\n",
    "\n",
    "print(f\"collected {len(sensor_data)} measurements during moving task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f4872-3264-4aa5-9353-083cc594bccd",
   "metadata": {},
   "source": [
    "The data collected by the robot can be visualized on the rerun panel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e447671-7960-4c15-ae83-a3beba1ccc42",
   "metadata": {},
   "source": [
    "## Scaling up the generation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b3b5e0-b635-4c20-87ac-097fd5c036f8",
   "metadata": {},
   "source": [
    "To effectively scale up data generation, it’s crucial to simulate diverse real-world conditions and scenarios. Here, we randomize environmental parameters such as weather, wind, and time of day to introduce variability, creating a richer dataset that enhances model robustness. Additionally, GRID allows generating multiple trajectories, enabling the robot to navigate different paths under varied conditions. This combination of dynamic settings and paths ensures scalable, consistent data generation across multiple sessions, supporting efficient large-scale projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94693f90-2b9a-41ce-8114-0dca076b55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, h5py, numpy as np\n",
    "from airgen import WeatherParameter, Vector3r\n",
    "from grid import GRID_USER_SESSION_BLOB_DIR\n",
    "\n",
    "\n",
    "save_path = os.path.join(GRID_USER_SESSION_BLOB_DIR, \"sensor_data.h5\")\n",
    "\n",
    "client.simEnableWeather(True)\n",
    "\n",
    "# Generate data for multiple trajectories\n",
    "num_trajectories = 5\n",
    "weather_options = [\n",
    "    WeatherParameter.Rain, WeatherParameter.Roadwetness, WeatherParameter.Snow,\n",
    "    WeatherParameter.RoadSnow, WeatherParameter.MapleLeaf, WeatherParameter.RoadLeaf,\n",
    "    WeatherParameter.Dust, WeatherParameter.Fog\n",
    "]\n",
    "\n",
    "with h5py.File(save_path, 'a') as hdf5_file:  # Open the file in append mode once\n",
    "    for traj_idx in range(num_trajectories):\n",
    "        client.simSetWeatherParameter(random.choice(weather_options), random.uniform(0, 1))\n",
    "        client.simSetTimeOfDay(True, f\"2024-07-22 {random.randint(0, 23):02}:{random.randint(0, 59):02}:00\")\n",
    "\n",
    "        path = client.simPlanPathToRandomFreePoint(100, smooth_path=True, draw_path=True)\n",
    "        points = [Vector3r(p['x_val'], p['y_val'], p['z_val']) for p in path]\n",
    "\n",
    "        _, sensor_data = move_task(client, (0, 0, -10), _collect_data=True)\n",
    "\n",
    "        # Create a group for each trajectory\n",
    "        traj_group = hdf5_file.create_group(f\"trajectory_{traj_idx}\")\n",
    "\n",
    "        for i, data in enumerate(sensor_data):\n",
    "            # Create subgroup for each frame\n",
    "            frame_group = traj_group.create_group(f\"frame_{i}\")\n",
    "            frame_group.create_dataset(\"rgb\", data=data[\"rgb\"][0])\n",
    "            frame_group.create_dataset(\"lidar\", data=np.array(data[\"lidar\"].point_cloud).reshape(-1, 3))\n",
    "\n",
    "            # Logging for visualization if required\n",
    "            rr.log(\"grid/imagery\", rr.Image(data[\"rgb\"][0]))\n",
    "            rr.log(\"pointcloud\", rr.Points3D(np.array(data[\"lidar\"].point_cloud).reshape(-1, 3)))\n",
    "\n",
    "        print(f\"Collected {len(sensor_data)} measurements for trajectory {traj_idx + 1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706abecb-9b16-4e46-9d36-37035955f585",
   "metadata": {},
   "source": [
    "Once the robot has explored all the trajectories by itself, the entire sensor data will be stored in the `sensor_data.h5` file which you can download and store in your own system and integrate with your pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200895fb-6881-426f-8572-79efa61cddd9",
   "metadata": {},
   "source": [
    "# GRID Enterprise - Parallelisation and Optimisation\n",
    "\n",
    "To optimize and scale data collection processes, GRID Enterprise enables parallelization across multiple sessions. This feature allows for efficient generation of large datasets by running multiple instances simultaneously, significantly reducing time and computational resources needed for large-scale projects.\n",
    "\n",
    "Please refer to our [GRID-Enterprise tutorial](https://github.com/ScaledFoundations/GRID-playground/blob/main/grid-samples/datagen_enterprise.ipynb) for more information\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
