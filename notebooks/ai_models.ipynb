{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09473d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid.robot.aerial.airgen_drone import AirGenDrone \n",
    "airgen_drone__0 = AirGenDrone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "airgen_drone_0.client.takeoffAsync().join()\n",
    "airgen_drone_0.client.moveToZAsync(-25, 2).join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9282dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import airgen\n",
    "import numpy as np\n",
    "from grid.model.perception.detection.gdino import GroundingDINO\n",
    "\n",
    "groundingdino = GroundingDINO()\n",
    "\n",
    "# Define a detect function that captures an RGB image from the front camera and uses an object detector\n",
    "\n",
    "def detect(drone, object_name=\"fire\"):\n",
    "    rgb_image, pose = drone.getImages(\"front_center\", [airgen.ImageType.Scene])[0]\n",
    "    boxes, phrases = groundingdino.detect_object(rgb_image, object_name)\n",
    "    return boxes, phrases\n",
    "\n",
    "# Let's search for the fire by rotating 360 degrees and trying to detect fire at each step\n",
    "yaw_angles = np.linspace(0, 360, 30)\n",
    "\n",
    "for yaw in yaw_angles:\n",
    "    airgen_drone_0.client.rotateToYawAsync(yaw).join()\n",
    "    boxes, phrases = detect(airgen_drone_0.client)\n",
    "    if 'fire' in phrases:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to use a different model and object category\n",
    "\n",
    "from grid.model.perception.segmentation.clipseg import CLIPSeg\n",
    "clipseg = CLIPSeg()\n",
    "\n",
    "# Use CLIP features to try and segment out 'smoke'\n",
    "\n",
    "def segment(drone_client, object_name=\"smoke\"):\n",
    "    rgb_image, pose = drone_client.getImages(\"front_center\", [airgen.ImageType.Scene])[0]\n",
    "    result = clipseg.segment_image(rgb_image, object_name)\n",
    "    return result\n",
    "\n",
    "segment(airgen_drone_0.client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the vision models with some weather variations to the scene\n",
    "import time\n",
    "airgen_drone_0.client.simEnableWeather(True)\n",
    "\n",
    "for i in range(10):\n",
    "    airgen_drone_0.client.simSetWeatherParameter(airgen.WeatherParameter.Rain, i / 10)\n",
    "    airgen_drone_0.client.simSetWeatherParameter(airgen.WeatherParameter.Fog, i / 10)\n",
    "    detect(airgen_drone_0.client)\n",
    "    segment(airgen_drone_0.client)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
