{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66816d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid.model.perception.depth.metric3d import Metric3D\n",
    "depth_metric3d_0 = Metric3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell everytime you want to compute the point cloud from rgb image\n",
    "# We use Metric3d model along with utilities built in airgen to compute and\n",
    "# visualise the point cloud in rerun. We also get the depth map here to see\n",
    "# how it looks\n",
    "\n",
    "import numpy as np\n",
    "import airgen\n",
    "from PIL import Image\n",
    "import rerun as rr\n",
    "from airgen.utils.vision import depth2pointcloud\n",
    "\n",
    "client = airgen.VehicleClient()\n",
    "\n",
    "images = client.getImages(\"front_center\", [airgen.ImageType.Scene, airgen.ImageType.DepthPerspective])\n",
    "capture = {\n",
    "        \"front_rgb\": images[0],\n",
    "        \"front_depth\": images[1],\n",
    "    }\n",
    "\n",
    "for camera_name, camera_data in capture.items():\n",
    "    if camera_name == \"front_depth\":\n",
    "        # compute point cloud and visualize it in rerun\n",
    "        # remove points that are too far away\n",
    "        mask = np.where(camera_data[0] < 1000.0, 1, 0).astype(np.uint8)\n",
    "        point_cloud = depth2pointcloud(\n",
    "            depth=camera_data[0], camera_param=camera_data[1], mask=mask\n",
    "        )\n",
    "        print(point_cloud.shape)\n",
    "        print(camera_data[0].shape)\n",
    "        rr.log('grid/point_cloud', rr.Points3D(positions = point_cloud))\n",
    "        rr.log('grid/depth_ground_truth', rr.DepthImage(camera_data[0]))\n",
    "    else:\n",
    "        print(camera_data[0].shape)\n",
    "        rr.log('grid/rgb', rr.Image(camera_data[0]))\n",
    "        depth_map_pred = depth_metric3d_0.run(camera_data[0])\n",
    "        print(\"Predicted Depth map shape:\", depth_map_pred.shape)\n",
    "        # reshape to be compliant to the depth2pointcloud api\n",
    "        depth_map_3d_reshape = depth_map_pred.reshape((256, 256, 1))\n",
    "        mask = np.where(depth_map_3d_reshape < 150.0, 1, 0).astype(np.uint8)\n",
    "        point_cloud = depth2pointcloud(\n",
    "            depth=depth_map_3d_reshape, camera_param=camera_data[1], mask = mask\n",
    "        )\n",
    "        print(\"Predicted Depth map after reshape:\", depth_map_3d_reshape.shape)\n",
    "        rr.log('grid/point_cloud_predicted', rr.Points3D(positions = point_cloud))\n",
    "        rr.log('grid/depth_predicted', rr.DepthImage(depth_map_3d_reshape))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
